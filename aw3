const express = require("express");
const axios = require("axios");
const fs = require("fs").promises;
const path = require("path");
const crypto = require("crypto");
const cluster = require("cluster");
const os = require("os");
const { HttpsProxyAgent } = require("https-proxy-agent");

// Optimize for high RAM usage (16GB)
const MEMORY_OPTIMIZATION = {
  maxOldSpaceSize: 14 * 1024, // 14GB untuk Node.js heap
  maxConcurrentRequests: 500,  // Tingkatkan concurrent requests
  proxyTestConcurrency: 100,   // Tingkatkan proxy testing concurrency
  batchSize: 500,              // Tingkatkan batch size
  maxBufferSize: 512 * 1024 * 1024, // 512MB buffer untuk large responses
  preloadProxies: 10000,       // Preload lebih banyak proxies di memory
  cachePrewarm: true,          // Enable cache prewarming
  memoryBuffer: 4 * 1024 * 1024 * 1024 // 4GB memory buffer
};

const app = express();
const PORT = process.env.PORT || 3000;

// Enhanced p-limit with higher concurrency
function createLimit(concurrency) {
  let running = 0;
  const queue = [];
  
  return function limit(fn) {
    return new Promise((resolve, reject) => {
      queue.push({ fn, resolve, reject });
      tryNext();
    });
  };
  
  function tryNext() {
    if (running >= concurrency || queue.length === 0) return;
    
    running++;
    const { fn, resolve, reject } = queue.shift();
    
    Promise.resolve(fn())
      .then(resolve, reject)
      .finally(() => {
        running--;
        tryNext();
      });
  }
}

// Expanded proxy sources for better diversity
const proxySources = [
  "https://api.proxyscrape.com/v4/free-proxy-list/get?request=get_proxies&protocol=http&proxy_format=ipport&format=text&timeout=20000",
  "https://proxylist.geonode.com/api/proxy-list?protocols=http%2Chttps&limit=500&page=1&sort_by=lastChecked&sort_type=desc",
  "https://raw.githubusercontent.com/proxifly/free-proxy-list/refs/heads/main/proxies/protocols/http/data.txt",
  "https://raw.githubusercontent.com/ebrasha/abdal-proxy-hub/refs/heads/main/http-proxy-list-by-EbraSha.txt",
  "https://raw.githubusercontent.com/dpangestuw/Free-Proxy/refs/heads/main/http_proxies.txt",
  "https://raw.githubusercontent.com/elliottophellia/proxylist/refs/heads/master/results/mix_checked.txt",
  "https://raw.githubusercontent.com/monosans/proxy-list/refs/heads/main/proxies/http.txt",
  "https://raw.githubusercontent.com/databay-labs/free-proxy-list/refs/heads/master/http.txt",
  "https://raw.githubusercontent.com/MrMarble/proxy-list/refs/heads/main/all.txt",
  "https://raw.githubusercontent.com/saisuiu/Lionkings-Http-Proxys-Proxies/refs/heads/main/free.txt",
  "https://raw.githubusercontent.com/vmheaven/VMHeaven-Free-Proxy-Updated/refs/heads/main/http.txt",
  "https://raw.githubusercontent.com/vmheaven/VMHeaven-Free-Proxy-Updated/refs/heads/main/https.txt",
  "https://raw.githubusercontent.com/iplocate/free-proxy-list/refs/heads/main/protocols/http.txt",
  // Additional sources for better coverage
  "https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt",
  "https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list-raw.txt",
  "https://raw.githubusercontent.com/sunny9577/proxy-scraper/master/proxies.txt",
  "https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-http.txt",
  "https://raw.githubusercontent.com/mertguvencli/http-proxy-list/main/proxy-list/data.txt"
];

// ===============================
// MEMORY-OPTIMIZED CACHE SYSTEM (unchanged as requested)
// ===============================
class FileBasedSmartCache {
  constructor() {
    this.cacheFile = path.join(__dirname, 'cache.txt');
    this.maxCacheSize = 200 * 1024 * 1024; // Keep 200MB as requested
    this.resetInterval = 3 * 60 * 60 * 1000; // 3 hours
    this.maxFileSize = 50 * 1024 * 1024; // Keep 50MB as requested
    
    // Enhanced memory buffers for performance
    this.memoryCache = new Map(); // In-memory cache for frequent requests
    this.memoryCacheSize = 0;
    this.maxMemoryCacheSize = 500 * 1024 * 1024; // 500MB in-memory cache
    this.memoryCacheTTL = 30 * 60 * 1000; // 30 minutes TTL for memory cache
    
    // Enhanced stats tracking
    this.stats = {
      hitCount: 0,
      missCount: 0,
      skipCount: 0,
      evictedCount: 0,
      resetCount: 0,
      lastReset: new Date(),
      currentCacheSize: 0,
      totalEntries: 0,
      memoryHits: 0,
      memoryMisses: 0,
      memoryEvictions: 0
    };
    
    this.streamingExtensions = new Set([
      '.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v',
      '.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a',
      '.zip', '.rar', '.7z', '.tar', '.gz',
      '.iso', '.bin', '.dmg'
    ]);
    
    this.initializeCache();
    this.startResetTimer();
    this.startMemoryCleanup();
  }

  startMemoryCleanup() {
    // Clean memory cache every 5 minutes
    setInterval(() => {
      this.cleanMemoryCache();
    }, 5 * 60 * 1000);
  }

  cleanMemoryCache() {
    const now = Date.now();
    let cleaned = 0;
    let freedSize = 0;
    
    for (const [key, value] of this.memoryCache.entries()) {
      if (now - value.timestamp > this.memoryCacheTTL) {
        freedSize += value.size;
        this.memoryCache.delete(key);
        cleaned++;
      }
    }
    
    this.memoryCacheSize -= freedSize;
    this.stats.memoryEvictions += cleaned;
    
    if (cleaned > 0) {
      console.log(`ðŸ§¹ Memory cache cleanup: ${cleaned} entries removed, ${Math.round(freedSize/1024/1024)}MB freed`);
    }
  }

  async initializeCache() {
    try {
      try {
        await fs.access(this.cacheFile);
        await this.updateCacheStats();
        console.log('ðŸ’¾ Cache file found, stats updated');
      } catch (error) {
        await fs.writeFile(this.cacheFile, '{}');
        console.log('ðŸ’¾ Cache file created');
      }
    } catch (error) {
      console.error('âŒ Error initializing cache:', error.message);
    }
  }

  async updateCacheStats() {
    try {
      const stats = await fs.stat(this.cacheFile);
      this.stats.currentCacheSize = stats.size;
      
      const content = await fs.readFile(this.cacheFile, 'utf8');
      const cache = JSON.parse(content);
      this.stats.totalEntries = Object.keys(cache).length;
    } catch (error) {
      console.error('âŒ Error updating cache stats:', error.message);
    }
  }

  generateKey(url) {
    return crypto.createHash('md5').update(url).digest('hex');
  }

  shouldCache(url, contentType, contentLength, headers) {
    if (contentLength && contentLength > this.maxFileSize) {
      return false;
    }

    if (contentType) {
      const type = contentType.toLowerCase();
      if (type.includes('video/') || 
          type.includes('audio/') || 
          type.includes('application/octet-stream') ||
          type.includes('application/zip') ||
          type.includes('application/x-rar')) {
        return false;
      }
    }

    const urlPath = new URL(url).pathname.toLowerCase();
    for (const ext of this.streamingExtensions) {
      if (urlPath.includes(ext)) {
        return false;
      }
    }

    if (headers && headers['accept-ranges']) {
      return false;
    }

    return true;
  }

  async set(url, data, headers, contentType) {
    try {
      const dataBuffer = Buffer.isBuffer(data) ? data : Buffer.from(data.toString());
      const contentLength = dataBuffer.length;
      
      if (!this.shouldCache(url, contentType, contentLength, headers)) {
        this.stats.skipCount++;
        console.log(`ðŸš« Skipping cache for streaming/large content: ${url} (${Math.round(contentLength/1024)}KB)`);
        return false;
      }

      const key = this.generateKey(url);
      
      // Add to memory cache first for fast access
      if (contentLength < 10 * 1024 * 1024 && // Only cache files < 10MB in memory
          this.memoryCacheSize + contentLength < this.maxMemoryCacheSize) {
        this.memoryCache.set(key, {
          data: dataBuffer,
          headers: headers || {},
          contentType: contentType || 'application/octet-stream',
          timestamp: Date.now(),
          size: contentLength
        });
        this.memoryCacheSize += contentLength;
      }

      if (this.stats.currentCacheSize + contentLength > this.maxCacheSize) {
        console.log(`âš ï¸ Cache size limit would be exceeded, triggering cleanup`);
        await this.cleanupOldEntries();
        
        if (this.stats.currentCacheSize + contentLength > this.maxCacheSize) {
          this.stats.skipCount++;
          console.log(`ðŸš« Skipping cache due to size limit: ${url} (${Math.round(contentLength/1024)}KB)`);
          return false;
        }
      }

      const now = Date.now();
      
      let cache = {};
      try {
        const content = await fs.readFile(this.cacheFile, 'utf8');
        cache = JSON.parse(content);
      } catch (error) {
        cache = {};
      }

      cache[key] = {
        url: url,
        data: dataBuffer.toString('base64'),
        headers: headers || {},
        contentType: contentType || 'application/octet-stream',
        timestamp: now,
        hits: 0,
        size: contentLength
      };

      await fs.writeFile(this.cacheFile, JSON.stringify(cache));
      
      this.stats.currentCacheSize += contentLength;
      this.stats.totalEntries = Object.keys(cache).length;
      
      console.log(`ðŸ’¾ Cache stored: ${url} (${Math.round(contentLength/1024)}KB, ${this.stats.totalEntries} entries, ${Math.round(this.stats.currentCacheSize/1024/1024)}MB)`);
      return true;

    } catch (error) {
      console.error('âŒ Error setting cache:', error.message);
      return false;
    }
  }

  async get(url) {
    try {
      const key = this.generateKey(url);
      
      // Check memory cache first
      const memoryItem = this.memoryCache.get(key);
      if (memoryItem) {
        this.stats.memoryHits++;
        this.stats.hitCount++;
        console.log(`âš¡ Memory cache hit: ${url}`);
        return {
          data: memoryItem.data,
          headers: memoryItem.headers,
          contentType: memoryItem.contentType,
          hits: -1 // Indicate memory cache
        };
      }
      
      // Check file cache
      const content = await fs.readFile(this.cacheFile, 'utf8');
      const cache = JSON.parse(content);
      
      const item = cache[key];
      if (!item) {
        this.stats.missCount++;
        this.stats.memoryMisses++;
        return null;
      }
      
      item.hits++;
      cache[key] = item;
      
      fs.writeFile(this.cacheFile, JSON.stringify(cache)).catch(err => {
        console.error('âŒ Error updating hit count:', err.message);
      });
      
      this.stats.hitCount++;
      
      return {
        data: Buffer.from(item.data, 'base64'),
        headers: item.headers,
        contentType: item.contentType,
        hits: item.hits
      };

    } catch (error) {
      console.error('âŒ Error getting from cache:', error.message);
      this.stats.missCount++;
      return null;
    }
  }

  async invalidate(url) {
    try {
      const key = this.generateKey(url);
      
      // Remove from memory cache
      const memoryItem = this.memoryCache.get(key);
      if (memoryItem) {
        this.memoryCacheSize -= memoryItem.size;
        this.memoryCache.delete(key);
      }
      
      const content = await fs.readFile(this.cacheFile, 'utf8');
      const cache = JSON.parse(content);
      
      if (cache[key]) {
        this.stats.currentCacheSize -= (cache[key].size || 0);
        delete cache[key];
        
        await fs.writeFile(this.cacheFile, JSON.stringify(cache));
        this.stats.totalEntries = Object.keys(cache).length;
        
        console.log(`ðŸ—‘ï¸ Cache invalidated: ${url}`);
        return true;
      }
      
      return false;
    } catch (error) {
      console.error('âŒ Error invalidating cache:', error.message);
      return false;
    }
  }

  async clear() {
    try {
      await fs.writeFile(this.cacheFile, '{}');
      const oldSize = this.stats.currentCacheSize;
      const oldEntries = this.stats.totalEntries;
      
      // Clear memory cache
      this.memoryCache.clear();
      this.memoryCacheSize = 0;
      
      this.stats.currentCacheSize = 0;
      this.stats.totalEntries = 0;
      
      console.log(`ðŸ—‘ï¸ Cache cleared: ${oldEntries} entries (${Math.round(oldSize/1024/1024)}MB) removed`);
      return true;
    } catch (error) {
      console.error('âŒ Error clearing cache:', error.message);
      return false;
    }
  }

  async cleanupOldEntries() {
    try {
      const content = await fs.readFile(this.cacheFile, 'utf8');
      const cache = JSON.parse(content);
      
      const entries = Object.entries(cache).sort((a, b) => {
        const scoreA = a[1].timestamp + (a[1].hits * 1000 * 60 * 60);
        const scoreB = b[1].timestamp + (b[1].hits * 1000 * 60 * 60);
        return scoreA - scoreB;
      });
      
      const removeCount = Math.ceil(entries.length * 0.2);
      const newCache = {};
      let removedSize = 0;
      
      for (let i = removeCount; i < entries.length; i++) {
        const [key, value] = entries[i];
        newCache[key] = value;
      }
      
      for (let i = 0; i < removeCount; i++) {
        removedSize += entries[i][1].size || 0;
      }
      
      await fs.writeFile(this.cacheFile, JSON.stringify(newCache));
      
      this.stats.currentCacheSize -= removedSize;
      this.stats.totalEntries = Object.keys(newCache).length;
      this.stats.evictedCount += removeCount;
      
      console.log(`ðŸ§¹ Cache cleanup: ${removeCount} entries removed (${Math.round(removedSize/1024/1024)}MB freed)`);
      
    } catch (error) {
      console.error('âŒ Error during cleanup:', error.message);
    }
  }

  startResetTimer() {
    setInterval(async () => {
      await this.resetCache();
    }, this.resetInterval);

    console.log(`â° Cache reset timer started (every 3 hours)`);
  }

  async resetCache() {
    try {
      const oldSize = this.stats.currentCacheSize;
      const oldEntries = this.stats.totalEntries;
      const oldHits = this.stats.hitCount;
      const oldMisses = this.stats.missCount;
      const oldSkips = this.stats.skipCount;
      const oldMemoryHits = this.stats.memoryHits;
      
      await fs.writeFile(this.cacheFile, '{}');
      
      // Clear memory cache
      this.memoryCache.clear();
      this.memoryCacheSize = 0;
      
      this.stats = {
        hitCount: 0,
        missCount: 0,
        skipCount: 0,
        evictedCount: 0,
        resetCount: this.stats.resetCount + 1,
        lastReset: new Date(),
        currentCacheSize: 0,
        totalEntries: 0,
        memoryHits: 0,
        memoryMisses: 0,
        memoryEvictions: 0
      };
      
      console.log(`ðŸ”„ SCHEDULED CACHE RESET #${this.stats.resetCount}`);
      console.log(`   ðŸ“Š Previous session stats:`);
      console.log(`   ðŸ’¾ File Cache: ${Math.round(oldSize/1024/1024)}MB (${oldEntries} entries)`);
      console.log(`   ðŸš€ Memory Hits: ${oldMemoryHits}, File Hits: ${oldHits - oldMemoryHits}`);
      console.log(`   ðŸŽ¯ Total Hits: ${oldHits}, Misses: ${oldMisses}, Skips: ${oldSkips}`);
      console.log(`   ðŸ“ˆ Hit Rate: ${oldHits + oldMisses > 0 ? Math.round(oldHits/(oldHits + oldMisses)*100) : 0}%`);
      
    } catch (error) {
      console.error('âŒ Error during scheduled cache reset:', error.message);
    }
  }

  getStats() {
    const totalRequests = this.stats.hitCount + this.stats.missCount + this.stats.skipCount;
    const hitRate = totalRequests > 0 ? ((this.stats.hitCount / totalRequests) * 100).toFixed(2) + '%' : '0%';
    const skipRate = totalRequests > 0 ? ((this.stats.skipCount / totalRequests) * 100).toFixed(2) + '%' : '0%';
    const memoryHitRate = this.stats.hitCount > 0 ? ((this.stats.memoryHits / this.stats.hitCount) * 100).toFixed(2) + '%' : '0%';
    
    const nextReset = new Date(this.stats.lastReset.getTime() + this.resetInterval);
    const timeToReset = Math.max(0, nextReset.getTime() - Date.now());
    
    return {
      totalEntries: this.stats.totalEntries,
      currentCacheSize: this.stats.currentCacheSize,
      maxCacheSize: this.maxCacheSize,
      hitCount: this.stats.hitCount,
      missCount: this.stats.missCount,
      skipCount: this.stats.skipCount,
      evictedCount: this.stats.evictedCount,
      hitRate: hitRate,
      skipRate: skipRate,
      memoryStats: {
        memoryHits: this.stats.memoryHits,
        memoryHitRate: memoryHitRate,
        memoryCacheSize: this.memoryCacheSize,
        maxMemoryCacheSize: this.maxMemoryCacheSize,
        memoryCacheEntries: this.memoryCache.size,
        memoryEvictions: this.stats.memoryEvictions
      },
      resetCount: this.stats.resetCount,
      lastReset: this.stats.lastReset,
      nextReset: nextReset,
      timeToNextReset: Math.round(timeToReset / 1000 / 60) + ' minutes',
      resetInterval: '3 hours',
      maxFileSize: this.maxFileSize,
      sizeMB: Math.round(this.stats.currentCacheSize / 1024 / 1024 * 100) / 100,
      maxSizeMB: Math.round(this.maxCacheSize / 1024 / 1024),
      sizeUsagePercent: Math.round((this.stats.currentCacheSize / this.maxCacheSize) * 100),
      avgFileSize: this.stats.totalEntries > 0 ? Math.round(this.stats.currentCacheSize / this.stats.totalEntries) : 0,
      cacheStrategy: 'Hybrid: File-based + In-memory with 3-hour auto-reset',
      streamingSupport: 'Videos bypass cache automatically'
    };
  }

  destroy() {
    this.memoryCache.clear();
    console.log('ðŸ”„ Cache manager shutting down...');
  }
}

// ===============================
// HIGH-PERFORMANCE PROXY MANAGER - OPTIMIZED FOR 16GB RAM
// ===============================
class ProxyManager {
  constructor() {
    this.workingProxies = new Map();
    this.allProxies = new Set();
    this.deadProxies = new Map();
    this.testingQueue = new Set();
    this.fastProxies = new Set();
    
    // Memory optimization: Keep more proxies in memory
    this.proxyMetadata = new Map(); // Detailed metadata for each proxy
    this.proxyPerformance = new Map(); // Performance tracking
    this.proxyGeolocation = new Map(); // Geo data for proxy selection
    this.recentRequests = new Map(); // Track recent request patterns
    
    // Enhanced queueing system for high concurrency
    this.requestQueue = [];
    this.activeRequests = 0;
    this.maxActiveRequests = MEMORY_OPTIMIZATION.maxConcurrentRequests;
    
    this.isFetching = false;
    this.isTesting = false;
    this.testingProgress = { current: 0, total: 0, batch: 0 };
    
    this.stats = {
      totalFetched: 0,
      totalTested: 0,
      totalWorking: 0,
      totalDead: 0,
      testingSessions: 0,
      lastUpdate: null,
      lastFullScan: null,
      avgTestTime: 0,
      totalTestTime: 0,
      racingWins: 0,
      instantSwitches: 0,
      memoryUsage: 0,
      proxiesInMemory: 0,
      performanceOptimizations: 0
    };
    
    this.intervals = {};
    
    // Start memory monitoring
    this.startMemoryMonitoring();
    this.startRequestQueueProcessor();
  }

  startMemoryMonitoring() {
    setInterval(() => {
      const usage = process.memoryUsage();
      this.stats.memoryUsage = Math.round(usage.heapUsed / 1024 / 1024);
      this.stats.proxiesInMemory = this.workingProxies.size + this.deadProxies.size;
      
      // Auto-optimize if memory usage is low
      if (this.stats.memoryUsage < 8000 && this.workingProxies.size > 0) { // Less than 8GB
        this.optimizeProxySelection();
      }
    }, 30000); // Every 30 seconds
  }

  optimizeProxySelection() {
    // Pre-calculate proxy scores for faster selection
    for (const [proxy, metadata] of this.workingProxies.entries()) {
      const score = this.calculateProxyScore(metadata);
      this.proxyPerformance.set(proxy, {
        ...this.proxyPerformance.get(proxy) || {},
        score: score,
        lastCalculated: Date.now()
      });
    }
    this.stats.performanceOptimizations++;
  }

  startRequestQueueProcessor() {
    // Process request queue with high concurrency
    setInterval(() => {
      while (this.requestQueue.length > 0 && 
             this.activeRequests < this.maxActiveRequests) {
        const request = this.requestQueue.shift();
        this.activeRequests++;
        
        this.processRequest(request).finally(() => {
          this.activeRequests--;
        });
      }
    }, 10); // Process every 10ms for high throughput
  }

  async processRequest(request) {
    // Implementation would go here for processing queued requests
    return request;
  }

  async fetchProxies() {
    if (this.isFetching) {
      console.log("â³ Fetch already in progress, skipping...");
      return this.allProxies;
    }

    this.isFetching = true;
    console.log("ðŸ”„ Fetching proxies from all sources with high concurrency...");
    let newProxies = [];
    
    // Use higher concurrency for fetching
    const fetchPromises = proxySources.map(async (url, index) => {
      try {
        console.log(`ðŸ“¡ [${index + 1}/${proxySources.length}] Fetching from: ${url.split('/')[2]}`);
        const res = await axios.get(url, { 
          timeout: 15000, // Reduced timeout for faster processing
          maxRedirects: 3,
          maxContentLength: MEMORY_OPTIMIZATION.maxBufferSize
        });
        
        let proxies = [];
        if (url.includes("geonode")) {
          if (res.data && res.data.data) {
            proxies = res.data.data.map(p => `${p.ip}:${p.port}`);
          }
        } else {
          proxies = res.data
            .split("\n")
            .map(l => l.trim().replace(/^http(s)?:\/\//, ""))
            .filter(l => l && l.includes(':') && l.split(':').length === 2)
            .filter(l => {
              const [ip, port] = l.split(':');
              return ip.match(/^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$/) && 
                     port.match(/^\d+$/) && 
                     parseInt(port) > 0 && 
                     parseInt(port) < 65536;
            });
        }
        
        newProxies.push(...proxies);
        console.log(`âœ… [${index + 1}/${proxySources.length}] Got ${proxies.length} proxies from: ${url.split('/')[2]}`);
        return proxies.length;
      } catch (err) {
        console.log(`âŒ [${index + 1}/${proxySources.length}] Failed: ${url.split('/')[2]} - ${err.message}`);
        return 0;
      }
    });
    
    const results = await Promise.allSettled(fetchPromises);
    const totalFetched = results.reduce((sum, result) => {
      return sum + (result.status === 'fulfilled' ? result.value : 0);
    }, 0);
    
    const uniqueProxies = [...new Set(newProxies)];
    const beforeSize = this.allProxies.size;
    
    // Add all proxies to memory with enhanced tracking
    uniqueProxies.forEach(proxy => {
      this.allProxies.add(proxy);
      
      // Initialize metadata for better memory utilization
      if (!this.proxyMetadata.has(proxy)) {
        this.proxyMetadata.set(proxy, {
          addedAt: new Date(),
          source: 'multiple',
          attempts: 0,
          lastSeen: new Date()
        });
      }
    });
    
    const newCount = this.allProxies.size - beforeSize;
    
    this.stats.totalFetched = this.allProxies.size;
    this.stats.lastUpdate = new Date();
    
    console.log(`ðŸ“Š Fetch complete: ${uniqueProxies.length} total, ${newCount} new, ${this.allProxies.size} unique proxies`);
    console.log(`ðŸ’¾ Memory usage: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`);
    
    this.isFetching = false;
    return this.allProxies;
  }

  async testProxy(proxy, testUrls = [
    "https://otakudesu.best/anime/watanare-sub-indo", 
    "https://v1.samehadaku.how",
    "https://httpbin.org/ip",
    "https://api.github.com"
  ]) {
    const startTime = Date.now();
    
    // Update metadata
    const metadata = this.proxyMetadata.get(proxy) || {};
    metadata.attempts = (metadata.attempts || 0) + 1;
    metadata.lastTested = new Date();
    this.proxyMetadata.set(proxy, metadata);
    
    for (const testUrl of testUrls) {
      try {
        const agent = new HttpsProxyAgent(`http://${proxy}`);
        const res = await axios.get(testUrl, {
          httpAgent: agent,
          httpsAgent: agent,
          timeout: 8000, // Reduced for faster testing
          maxRedirects: 2,
          validateStatus: () => true,
          maxContentLength: 5 * 1024 * 1024 // 5MB limit for test requests
        });
        
        const responseTime = Date.now() - startTime;
        
        if (res.status === 200 && res.data) {
          // Store performance data in memory
          this.proxyPerformance.set(proxy, {
            responseTime,
            testUrl,
            dataSize: Buffer.isBuffer(res.data) ? res.data.length : res.data.toString().length,
            successRate: 1.0,
            lastSuccess: new Date()
          });
          
          return { 
            proxy, 
            responseTime, 
            success: true, 
            testUrl,
            dataSize: Buffer.isBuffer(res.data) ? res.data.length : res.data.toString().length
          };
        }
      } catch (err) {
        continue;
      }
    }
    
    return { 
      proxy, 
      responseTime: Date.now() - startTime, 
      success: false 
    };
  }

  getBestWorkingProxy() {
    if (this.workingProxies.size === 0) return null;
    
    // Use pre-calculated scores if available for faster selection
    const sortedProxies = Array.from(this.workingProxies.entries())
      .map(([proxy, metadata]) => {
        const performance = this.proxyPerformance.get(proxy);
        const score = performance && performance.lastCalculated && 
                     (Date.now() - performance.lastCalculated < 60000) ? 
                     performance.score : this.calculateProxyScore(metadata);
        
        return {
          proxy,
          metadata,
          score
        };
      })
      .sort((a, b) => b.score - a.score);
    
    // Select from top 20% for better performance distribution
    const topCount = Math.max(1, Math.ceil(sortedProxies.length * 0.2));
    const randomIndex = Math.floor(Math.random() * topCount);
    
    const selectedProxy = sortedProxies[randomIndex].proxy;
    
    // Track recent usage
    this.recentRequests.set(selectedProxy, Date.now());
    
    return selectedProxy;
  }

  calculateProxyScore(metadata) {
    const successRate = metadata.successCount / (metadata.successCount + metadata.failCount);
    const responseScore = 1000 / (metadata.avgResponseTime + 100);
    const ageBonus = Math.min(1, (Date.now() - metadata.addedAt.getTime()) / (24 * 60 * 60 * 1000));
    
    // Add recent usage penalty to distribute load
    const recentUsage = this.recentRequests.get(metadata.proxy) || 0;
    const usagePenalty = Math.max(0, 1 - ((Date.now() - recentUsage) / 10000)); // 10 second cooldown
    
    return successRate * responseScore * (1 + ageBonus) * (1 - usagePenalty * 0.3);
  }

  removeFailedProxy(proxy) {
    if (this.workingProxies.has(proxy)) {
      const metadata = this.workingProxies.get(proxy);
      this.workingProxies.delete(proxy);
      this.fastProxies.delete(proxy);
      
      // Keep more detailed failure data in memory
      this.deadProxies.set(proxy, {
        lastTested: new Date(),
        failCount: metadata.failCount + 1,
        lastError: 'Request failed',
        originalMetadata: metadata,
        failureHistory: [
          ...(this.deadProxies.get(proxy)?.failureHistory || []).slice(-10), // Keep last 10 failures
          { timestamp: new Date(), reason: 'Request failed' }
        ]
      });
      
      this.stats.totalWorking = this.workingProxies.size;
      this.stats.totalDead = this.deadProxies.size;
      console.log(`ðŸ—‘ï¸ Removed failed proxy: ${proxy} (Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB)`);
    }
  }

  startBackgroundTasks() {
    console.log("ðŸš€ Starting high-performance proxy manager (16GB RAM optimized)...");
    
    this.fetchProxies().then(() => {
      setTimeout(() => this.testAllProxies(), 5000);
    });

    // More frequent fetching to maintain high proxy availability
    this.intervals.fetch = setInterval(async () => {
      await this.fetchProxies();
      if (!this.isTesting) {
        setTimeout(() => this.testAllProxies(), 5000); // Reduced delay
      }
    }, 20 * 60 * 1000); // Every 20 minutes instead of 30

    // Background proxy maintenance
    this.intervals.maintenance = setInterval(() => {
      this.maintainProxyPool();
    }, 5 * 60 * 1000); // Every 5 minutes

    // Clean up old data periodically
    this.intervals.cleanup = setInterval(() => {
      this.cleanupOldData();
    }, 10 * 60 * 1000); // Every 10 minutes
  }

  maintainProxyPool() {
    // Re-test potentially recovered proxies
    const now = Date.now();
    const retestThreshold = 30 * 60 * 1000; // 30 minutes
    
    let retestCandidates = [];
    for (const [proxy, data] of this.deadProxies.entries()) {
      if (now - data.lastTested.getTime() > retestThreshold && 
          data.failCount < 5) { // Don't retest heavily failed proxies
        retestCandidates.push(proxy);
      }
    }
    
    if (retestCandidates.length > 0) {
      console.log(`ðŸ”„ Re-testing ${retestCandidates.length} potentially recovered proxies...`);
      
      const limit = createLimit(20); // Test 20 concurrent
      const tasks = retestCandidates.slice(0, 50).map(proxy => // Limit to 50 at once
        limit(async () => {
          const result = await this.testProxy(proxy);
          if (result.success) {
            // Move back to working proxies
            this.deadProxies.delete(proxy);
            this.workingProxies.set(proxy, {
              successCount: 1,
              failCount: 0,
              totalResponseTime: result.responseTime,
              avgResponseTime: result.responseTime,
              lastTested: new Date(),
              addedAt: new Date(),
              successRate: 1.0,
              recoveredAt: new Date()
            });
            console.log(`âœ… Recovered proxy: ${proxy}`);
            return true;
          }
          return false;
        })
      );
      
      Promise.allSettled(tasks);
    }
  }

  cleanupOldData() {
    const now = Date.now();
    const cleanupAge = 6 * 60 * 60 * 1000; // 6 hours
    
    // Clean old performance data
    let cleanedPerformance = 0;
    for (const [proxy, data] of this.proxyPerformance.entries()) {
      if (now - (data.lastSuccess?.getTime() || 0) > cleanupAge) {
        this.proxyPerformance.delete(proxy);
        cleanedPerformance++;
      }
    }
    
    // Clean old request tracking
    let cleanedRequests = 0;
    for (const [proxy, timestamp] of this.recentRequests.entries()) {
      if (now - timestamp > 60000) { // 1 minute
        this.recentRequests.delete(proxy);
        cleanedRequests++;
      }
    }
    
    // Clean very old dead proxies to free memory
    let cleanedDead = 0;
    for (const [proxy, data] of this.deadProxies.entries()) {
      if (now - data.lastTested.getTime() > 24 * 60 * 60 * 1000 && // 24 hours old
          data.failCount > 10) { // And heavily failed
        this.deadProxies.delete(proxy);
        this.proxyMetadata.delete(proxy);
        cleanedDead++;
      }
    }
    
    if (cleanedPerformance > 0 || cleanedRequests > 0 || cleanedDead > 0) {
      console.log(`ðŸ§¹ Memory cleanup: ${cleanedPerformance} performance records, ${cleanedRequests} request records, ${cleanedDead} dead proxies removed`);
    }
  }

  async testAllProxies() {
    if (this.isTesting) return;
    this.isTesting = true;
    
    const untestedProxies = Array.from(this.allProxies).filter(proxy => 
      !this.workingProxies.has(proxy) && 
      !this.deadProxies.has(proxy) &&
      !this.testingQueue.has(proxy)
    );
    
    if (untestedProxies.length === 0) {
      this.isTesting = false;
      return;
    }

    console.log(`ðŸš€ Testing ${untestedProxies.length} proxies with high concurrency...`);
    
    // Use optimized settings for 16GB RAM
    const batchSize = MEMORY_OPTIMIZATION.batchSize; // 500
    const concurrency = MEMORY_OPTIMIZATION.proxyTestConcurrency; // 100
    const limit = createLimit(concurrency);
    
    let totalTested = 0;
    let batchNumber = 0;
    
    for (let i = 0; i < untestedProxies.length; i += batchSize) {
      batchNumber++;
      const batch = untestedProxies.slice(i, i + batchSize);
      
      console.log(`ðŸ“¦ Testing batch ${batchNumber}: ${batch.length} proxies (Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB)`);
      
      batch.forEach(proxy => this.testingQueue.add(proxy));
      
      const tasks = batch.map(proxy =>
        limit(async () => {
          const result = await this.testProxy(proxy);
          this.testingQueue.delete(proxy);
          
          const now = new Date();
          
          if (result.success) {
            this.workingProxies.set(proxy, {
              successCount: 1,
              failCount: 0,
              totalResponseTime: result.responseTime,
              avgResponseTime: result.responseTime,
              lastTested: now,
              addedAt: now,
              successRate: 1.0,
              proxy: proxy // Store proxy reference
            });
            
            // Add to fast proxies if response time is good
            if (result.responseTime < 3000) {
              this.fastProxies.add(proxy);
            }
          } else {
            this.deadProxies.set(proxy, {
              lastTested: now,
              failCount: 1,
              lastError: 'Connection failed',
              firstFailure: now
            });
          }
          
          totalTested++;
          return result;
        })
      );

      await Promise.allSettled(tasks);
      
      // Log progress with memory usage
      const memUsage = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
      console.log(`âœ… Batch ${batchNumber} complete: ${this.workingProxies.size} working, ${this.deadProxies.size} dead (Memory: ${memUsage}MB)`);
      
      // Small delay between batches to prevent overwhelming
      if (i + batchSize < untestedProxies.length) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    this.stats.totalWorking = this.workingProxies.size;
    this.stats.totalDead = this.deadProxies.size;
    this.stats.testingSessions++;
    
    const memUsage = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
    console.log(`âœ… Testing complete: ${this.workingProxies.size} working, ${this.deadProxies.size} dead proxies`);
    console.log(`ðŸ“Š Memory usage: ${memUsage}MB / ${Math.round(os.totalmem() / 1024 / 1024 / 1024)}GB total RAM`);
    console.log(`âš¡ Fast proxies: ${this.fastProxies.size}`);
    
    this.isTesting = false;
  }

  getStats() {
    const memUsage = process.memoryUsage();
    
    return {
      ...this.stats,
      workingProxiesCount: this.workingProxies.size,
      deadProxiesCount: this.deadProxies.size,
      totalProxiesCount: this.allProxies.size,
      fastProxiesCount: this.fastProxies.size,
      isTesting: this.isTesting,
      isFetching: this.isFetching,
      testingProgress: this.testingProgress,
      memory: {
        heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
        heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
        external: Math.round(memUsage.external / 1024 / 1024),
        arrayBuffers: Math.round(memUsage.arrayBuffers / 1024 / 1024),
        totalSystemRAM: Math.round(os.totalmem() / 1024 / 1024 / 1024),
        freeSystemRAM: Math.round(os.freemem() / 1024 / 1024 / 1024)
      },
      optimization: {
        maxConcurrentRequests: this.maxActiveRequests,
        activeRequests: this.activeRequests,
        queueLength: this.requestQueue.length,
        proxyMetadataCount: this.proxyMetadata.size,
        performanceRecords: this.proxyPerformance.size,
        recentRequestTracking: this.recentRequests.size
      },
      configuration: MEMORY_OPTIMIZATION
    };
  }

  destroy() {
    // Clear all intervals
    Object.values(this.intervals).forEach(interval => {
      if (interval) clearInterval(interval);
    });
    
    // Clear memory maps
    this.proxyMetadata.clear();
    this.proxyPerformance.clear();
    this.proxyGeolocation.clear();
    this.recentRequests.clear();
    this.requestQueue.length = 0;
    
    console.log('ðŸ”„ High-performance proxy manager shutting down...');
  }
}

// ===============================
// ENHANCED FETCH WITH HIGHER CONCURRENCY AND MEMORY BUFFERING
// ===============================
async function fetchWithProxy(url, req, maxRetries = 12, useCache = true, cache) {
  const isRangeRequest = req.headers.range;
  
  if (isRangeRequest) {
    console.log(`ðŸ“¹ Range request detected for: ${url} (${req.headers.range})`);
    useCache = false;
  }

  if (useCache) {
    const cached = await cache.get(url);
    if (cached) {
      console.log(`âš¡ Cache hit: ${url} (${cached.hits === -1 ? 'Memory' : 'File'} cache)`);
      return {
        data: cached.data,
        headers: cached.headers,
        contentType: cached.contentType,
        fromCache: true,
        cacheHits: cached.hits
      };
    }
  }

  if (proxyManager.workingProxies.size === 0) {
    throw new Error(`No working proxies available`);
  }

  const startTime = Date.now();
  let usedProxies = new Set();
  let lastError = null;

  // Use more retries for better success rate with high RAM
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    const proxy = proxyManager.getBestWorkingProxy();
    
    if (!proxy || usedProxies.has(proxy)) {
      if (usedProxies.size >= Math.min(proxyManager.workingProxies.size, 20)) {
        usedProxies.clear();
      }
      if (!proxy) {
        throw new Error("No working proxies available");
      }
    }

    usedProxies.add(proxy);
    
    try {
      const agent = new HttpsProxyAgent(`http://${proxy}`);
      
      const proxyHeaders = {};
      
      if (req.headers.range) {
        proxyHeaders.Range = req.headers.range;
      }
      if (req.headers['user-agent']) {
        proxyHeaders['User-Agent'] = req.headers['user-agent'];
      }
      if (req.headers.referer) {
        proxyHeaders.Referer = req.headers.referer;
      }
      
      const response = await axios.get(url, {
        httpAgent: agent,
        httpsAgent: agent,
        timeout: isRangeRequest ? 20000 : 10000, // Increased timeouts
        maxRedirects: 3,
        validateStatus: () => true,
        responseType: 'arraybuffer',
        headers: proxyHeaders,
        maxContentLength: MEMORY_OPTIMIZATION.maxBufferSize, // 512MB max
        maxBodyLength: MEMORY_OPTIMIZATION.maxBufferSize
      });
      
      const duration = Date.now() - startTime;
      
      if (response.status === 200 || response.status === 206) {
        const contentType = response.headers['content-type'];
        const contentLength = response.headers['content-length'];
        
        // Update proxy success statistics
        if (proxyManager.workingProxies.has(proxy)) {
          const metadata = proxyManager.workingProxies.get(proxy);
          metadata.successCount = (metadata.successCount || 0) + 1;
          metadata.totalResponseTime = (metadata.totalResponseTime || 0) + duration;
          metadata.avgResponseTime = metadata.totalResponseTime / metadata.successCount;
          metadata.lastSuccess = new Date();
          proxyManager.workingProxies.set(proxy, metadata);
        }
        
        console.log(`âœ… Success with proxy: ${proxy} (${duration}ms, ${response.status}, ${Math.round(response.data.length/1024)}KB) [Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB]`);
        
        let cached = false;
        if (useCache && response.status === 200) {
          cached = await cache.set(url, response.data, response.headers, contentType);
        }
        
        return {
          data: response.data,
          headers: response.headers,
          contentType: contentType,
          proxy: proxy,
          duration: duration,
          attempts: attempt,
          fromCache: false,
          status: response.status,
          cached: cached,
          memoryUsage: Math.round(process.memoryUsage().heapUsed / 1024 / 1024)
        };
      } else {
        console.log(`âš ï¸ Non-success response from ${proxy}: ${response.status}`);
        lastError = `HTTP ${response.status}`;
        continue;
      }
      
    } catch (err) {
      lastError = err.message;
      console.log(`âŒ Failed with proxy: ${proxy} (attempt ${attempt}/${maxRetries}) - ${err.message}`);
      proxyManager.removeFailedProxy(proxy);
      
      if (attempt === maxRetries) {
        const duration = Date.now() - startTime;
        throw new Error(`All ${maxRetries} attempts failed after ${duration}ms. Last error: ${lastError}`);
      }
    }
  }
}

// Initialize managers
const proxyManager = new ProxyManager();
const cache = new FileBasedSmartCache();

// ===============================
// EXPRESS ROUTES WITH ENHANCED PERFORMANCE
// ===============================
app.use(express.json({ limit: '50mb' })); // Increased payload limit
app.use(express.urlencoded({ limit: '50mb', extended: true }));

app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Methods', 'GET, POST, DELETE, OPTIONS');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, Range');
  
  // Add performance headers
  res.header('X-Server-RAM', '16GB');
  res.header('X-Max-Concurrent', MEMORY_OPTIMIZATION.maxConcurrentRequests);
  res.header('X-Memory-Optimized', 'true');
  
  next();
});

// Enhanced main proxy endpoint
app.get('/proxies', async (req, res) => {
  const { url, nocache, timeout } = req.query;
  
  if (!url) {
    return res.status(400).json({ 
      error: 'URL parameter is required',
      example: '/proxies?url=https://example.com',
      optimizations: {
        memoryOptimized: '16GB RAM utilization',
        maxConcurrency: MEMORY_OPTIMIZATION.maxConcurrentRequests,
        cacheStrategy: 'Hybrid file + memory cache',
        videoStreaming: 'Full range request support'
      }
    });
  }

  try {
    new URL(url);
  } catch (err) {
    return res.status(400).json({ error: 'Invalid URL format' });
  }

  const startTime = Date.now();
  const useCache = nocache !== '1' && nocache !== 'true';
  const isRangeRequest = !!req.headers.range;

  try {
    console.log(`ðŸŒ Fetching: ${url} ${isRangeRequest ? '(RANGE REQUEST)' : ''} ${!useCache ? '(NO-CACHE)' : ''} [Memory: ${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB]`);
    
    const result = await fetchWithProxy(url, req, 12, useCache, cache);
    
    if (result.contentType) {
      res.set('Content-Type', result.contentType);
    }
    
    if (result.status === 206) {
      res.status(206);
      if (result.headers['content-range']) {
        res.set('Content-Range', result.headers['content-range']);
      }
      if (result.headers['accept-ranges']) {
        res.set('Accept-Ranges', result.headers['accept-ranges']);
      }
    }
    
    if (result.headers['content-length']) {
      res.set('Content-Length', result.headers['content-length']);
    }
    
    if (result.contentType && (result.contentType.includes('video/') || result.contentType.includes('audio/'))) {
      res.set('Accept-Ranges', 'bytes');
    }
    
    // Enhanced performance headers
    res.set('X-Proxy-Used', result.proxy || 'cache');
    res.set('X-Response-Time', `${result.duration || Date.now() - startTime}ms`);
    res.set('X-Attempts', result.attempts || 0);
    res.set('X-Cache-Status', result.fromCache ? 'HIT' : (result.cached ? 'STORED' : 'SKIP'));
    res.set('X-Available-Proxies', proxyManager.workingProxies.size);
    res.set('X-Content-Size', Math.round(result.data.length / 1024) + 'KB');
    res.set('X-Range-Request', isRangeRequest ? 'YES' : 'NO');
    res.set('X-Memory-Usage', `${result.memoryUsage || Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`);
    res.set('X-Fast-Proxies', proxyManager.fastProxies.size);
    res.set('X-High-Performance', 'enabled');
    
    res.send(result.data);
    
  } catch (err) {
    await cache.invalidate(url);
    
    const duration = Date.now() - startTime;
    const memUsage = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
    console.error(`âŒ Error after ${duration}ms (Memory: ${memUsage}MB):`, err.message);
    
    res.status(500).json({ 
      error: 'Failed to fetch URL through proxy',
      details: err.message,
      duration: `${duration}ms`,
      availableProxies: proxyManager.workingProxies.size,
      fastProxies: proxyManager.fastProxies.size,
      isRangeRequest: isRangeRequest,
      memoryUsage: `${memUsage}MB`,
      optimization: '16GB RAM optimized server',
      suggestion: 'Server automatically retries with multiple proxies and maintains high performance'
    });
  }
});

// Enhanced stats endpoint
app.get('/proxies/stats', async (req, res) => {
  await cache.updateCacheStats();
  const proxyStats = proxyManager.getStats();
  const cacheStats = cache.getStats();
  
  res.json({
    serverOptimization: {
      totalRAM: `${Math.round(os.totalmem() / 1024 / 1024 / 1024)}GB`,
      ramUtilization: 'High Performance Mode',
      maxConcurrency: MEMORY_OPTIMIZATION.maxConcurrentRequests,
      configuration: MEMORY_OPTIMIZATION
    },
    stats: proxyStats,
    cache: cacheStats,
    performance: {
      memoryOptimized: true,
      hybridCache: 'File + Memory',
      autoOptimization: true,
      highConcurrency: true
    }
  });
});

// Memory usage endpoint
app.get('/memory', (req, res) => {
  const usage = process.memoryUsage();
  const system = {
    total: os.totalmem(),
    free: os.freemem(),
    used: os.totalmem() - os.freemem()
  };
  
  res.json({
    process: {
      heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)}MB`,
      heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)}MB`,
      external: `${Math.round(usage.external / 1024 / 1024)}MB`,
      arrayBuffers: `${Math.round(usage.arrayBuffers / 1024 / 1024)}MB`,
      rss: `${Math.round(usage.rss / 1024 / 1024)}MB`
    },
    system: {
      total: `${Math.round(system.total / 1024 / 1024 / 1024)}GB`,
      used: `${Math.round(system.used / 1024 / 1024 / 1024)}GB`,
      free: `${Math.round(system.free / 1024 / 1024 / 1024)}GB`,
      utilization: `${Math.round((system.used / system.total) * 100)}%`
    },
    optimization: {
      targetHeapSize: `${MEMORY_OPTIMIZATION.maxOldSpaceSize / 1024}GB`,
      maxBufferSize: `${MEMORY_OPTIMIZATION.maxBufferSize / 1024 / 1024}MB`,
      memoryBuffer: `${MEMORY_OPTIMIZATION.memoryBuffer / 1024 / 1024 / 1024}GB`,
      status: 'High Performance Mode Active'
    },
    proxies: {
      inMemory: proxyManager.workingProxies.size + proxyManager.deadProxies.size,
      metadata: proxyManager.proxyMetadata?.size || 0,
      performance: proxyManager.proxyPerformance?.size || 0
    },
    cache: {
      memoryCache: cache.memoryCache?.size || 0,
      memoryCacheSize: `${Math.round((cache.memoryCacheSize || 0) / 1024 / 1024)}MB`
    }
  });
});

// Enhanced cache management
app.get('/proxies/cache', async (req, res) => {
  const showEntries = req.query.entries === '1';
  
  await cache.updateCacheStats();
  
  const response = {
    stats: cache.getStats(),
    fileBasedCache: {
      cacheFile: 'cache.txt',
      maxSize: '200MB',
      resetInterval: '3 hours',
      autoCleanup: 'Yes - removes oldest 20% when size limit reached'
    },
    memoryOptimization: {
      hybridCache: 'File + Memory cache for maximum performance',
      memoryCacheSize: `${Math.round((cache.memoryCacheSize || 0) / 1024 / 1024)}MB`,
      maxMemoryCache: `${Math.round(cache.maxMemoryCacheSize / 1024 / 1024)}MB`,
      memoryEntries: cache.memoryCache?.size || 0,
      memoryHitRate: cache.getStats().memoryStats?.memoryHitRate || '0%'
    },
    streamingSupport: {
      maxFileSize: Math.round(cache.maxFileSize / 1024 / 1024) + 'MB',
      skipExtensions: Array.from(cache.streamingExtensions),
      videoHandling: 'Videos bypass cache and support range requests'
    }
  };
  
  if (showEntries) {
    try {
      const content = await fs.readFile(cache.cacheFile, 'utf8');
      const cacheData = JSON.parse(content);
      
      response.entries = Object.values(cacheData)
        .map(entry => ({
          url: entry.url,
          contentType: entry.contentType || 'unknown',
          size: Math.round(entry.size / 1024) + 'KB',
          hits: entry.hits,
          age: Math.round((Date.now() - entry.timestamp) / 1000) + 's'
        }))
        .sort((a, b) => b.hits - a.hits)
        .slice(0, 100); // Show top 100 entries
        
    } catch (error) {
      response.entries = [];
      response.error = 'Could not read cache entries';
    }
  }
  
  res.json(response);
});

app.delete('/proxies/cache', async (req, res) => {
  const { url } = req.query;
  
  if (url) {
    const deleted = await cache.invalidate(url);
    res.json({ 
      message: deleted ? `Cache deleted for: ${url}` : `Cache entry not found: ${url}`,
      deleted,
      memoryUsage: `${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`
    });
  } else {
    const cleared = await cache.clear();
    res.json({ 
      message: cleared ? 'All cache cleared' : 'Failed to clear cache',
      cleared,
      memoryUsage: `${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`
    });
  }
});

// Force cache reset endpoint
app.post('/proxies/cache/reset', async (req, res) => {
  await cache.resetCache();
  res.json({ 
    message: 'Cache manually reset',
    nextAutoReset: new Date(Date.now() + cache.resetInterval),
    resetCount: cache.stats.resetCount,
    memoryUsage: `${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`
  });
});

// Enhanced proxy management endpoints
app.post('/proxies/test', async (req, res) => {
  if (proxyManager.isTesting) {
    return res.status(429).json({
      error: 'Testing already in progress',
      progress: proxyManager.testingProgress
    });
  }

  console.log('ðŸ§ª Manual proxy testing initiated...');
  
  // Start testing in background
  proxyManager.testAllProxies().then(() => {
    console.log('âœ… Manual proxy testing completed');
  });
  
  res.json({
    message: 'Proxy testing started',
    configuration: {
      batchSize: MEMORY_OPTIMIZATION.batchSize,
      concurrency: MEMORY_OPTIMIZATION.proxyTestConcurrency,
      memoryOptimized: true
    },
    estimatedTime: `${Math.ceil(proxyManager.allProxies.size / MEMORY_OPTIMIZATION.batchSize)} batches`,
    memoryUsage: `${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`
  });
});

app.post('/proxies/fetch', async (req, res) => {
  if (proxyManager.isFetching) {
    return res.status(429).json({
      error: 'Fetching already in progress'
    });
  }

  console.log('ðŸ“¡ Manual proxy fetching initiated...');
  
  try {
    const result = await proxyManager.fetchProxies();
    res.json({
      message: 'Proxy fetching completed',
      totalProxies: result.size,
      sources: proxySources.length,
      memoryUsage: `${Math.round(process.memoryUsage().heapUsed / 1024 / 1024)}MB`
    });
  } catch (error) {
    res.status(500).json({
      error: 'Failed to fetch proxies',
      details: error.message
    });
  }
});

// Performance monitoring endpoint
app.get('/performance', (req, res) => {
  const stats = proxyManager.getStats();
  const cacheStats = cache.getStats();
  const memUsage = process.memoryUsage();
  
  res.json({
    timestamp: new Date().toISOString(),
    server: {
      uptime: `${Math.round(process.uptime())}s`,
      memoryOptimization: '16GB RAM High Performance Mode',
      nodeVersion: process.version,
      platform: os.platform(),
      arch: os.arch(),
      cpus: os.cpus().length
    },
    memory: {
      process: {
        heapUsed: Math.round(memUsage.heapUsed / 1024 / 1024),
        heapTotal: Math.round(memUsage.heapTotal / 1024 / 1024),
        external: Math.round(memUsage.external / 1024 / 1024),
        arrayBuffers: Math.round(memUsage.arrayBuffers / 1024 / 1024)
      },
      system: {
        total: Math.round(os.totalmem() / 1024 / 1024 / 1024),
        free: Math.round(os.freemem() / 1024 / 1024 / 1024),
        used: Math.round((os.totalmem() - os.freemem()) / 1024 / 1024 / 1024)
      },
      optimization: MEMORY_OPTIMIZATION
    },
    proxies: {
      working: stats.workingProxiesCount,
      fast: stats.fastProxiesCount,
      dead: stats.deadProxiesCount,
      total: stats.totalProxiesCount,
      inMemoryMetadata: stats.optimization?.proxyMetadataCount || 0,
      performanceRecords: stats.optimization?.performanceRecords || 0
    },
    cache: {
      fileCache: {
        entries: cacheStats.totalEntries,
        sizeMB: cacheStats.sizeMB,
        hitRate: cacheStats.hitRate
      },
      memoryCache: {
        entries: cacheStats.memoryStats?.memoryCacheEntries || 0,
        sizeMB: Math.round((cache.memoryCacheSize || 0) / 1024 / 1024),
        hitRate: cacheStats.memoryStats?.memoryHitRate || '0%'
      }
    },
    concurrency: {
      maxConcurrentRequests: stats.optimization?.maxConcurrentRequests || 0,
      activeRequests: stats.optimization?.activeRequests || 0,
      queueLength: stats.optimization?.queueLength || 0
    }
  });
});

// Dashboard endpoint
app.get('/dashboard', (req, res) => {
  res.sendFile(path.join(__dirname, 'dashboard.html'));
});

// Enhanced health check with memory information
app.get('/health', async (req, res) => {
  const stats = proxyManager.getStats();
  await cache.updateCacheStats();
  const cacheStats = cache.getStats();
  const memUsage = process.memoryUsage();
  const systemMem = {
    total: os.totalmem(),
    free: os.freemem()
  };
  
  const health = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: Math.round(process.uptime()),
    server: {
      memoryOptimized: '16GB RAM High Performance Mode',
      maxConcurrency: MEMORY_OPTIMIZATION.maxConcurrentRequests,
      configuration: 'High Performance'
    },
    memory: {
      process: {
        used: Math.round(memUsage.heapUsed / 1024 / 1024),
        total: Math.round(memUsage.heapTotal / 1024 / 1024),
        external: Math.round(memUsage.external / 1024 / 1024),
        utilization: Math.round((memUsage.heapUsed / memUsage.heapTotal) * 100)
      },
      system: {
        total: Math.round(systemMem.total / 1024 / 1024 / 1024),
        free: Math.round(systemMem.free / 1024 / 1024 / 1024),
        used: Math.round((systemMem.total - systemMem.free) / 1024 / 1024 / 1024),
        utilization: Math.round(((systemMem.total - systemMem.free) / systemMem.total) * 100)
      }
    },
    proxies: {
      total: stats.totalProxiesCount,
      working: stats.workingProxiesCount,
      fast: stats.fastProxiesCount,
      dead: stats.deadProxiesCount,
      testing: stats.isTesting,
      fetching: stats.isFetching
    },
    cache: {
      type: 'hybrid-optimized',
      fileCache: {
        file: 'cache.txt',
        entries: cacheStats.totalEntries,
        sizeMB: cacheStats.sizeMB,
        hitRate: cacheStats.hitRate
      },
      memoryCache: {
        entries: cache.memoryCache?.size || 0,
        sizeMB: Math.round((cache.memoryCacheSize || 0) / 1024 / 1024),
        hitRate: cacheStats.memoryStats?.memoryHitRate || '0%',
        maxSizeMB: Math.round(cache.maxMemoryCacheSize / 1024 / 1024)
      },
      skipRate: cacheStats.skipRate,
      resetCount: cacheStats.resetCount,
      timeToNextReset: cacheStats.timeToNextReset
    },
    videoStreaming: {
      rangeRequestSupport: 'enabled',
      cacheBypass: 'automatic for videos',
      maxCacheFileSize: Math.round(cache.maxFileSize / 1024 / 1024) + 'MB'
    },
    performance: {
      highConcurrency: true,
      memoryOptimization: true,
      autoScaling: true,
      loadBalancing: true
    }
  };
  
  // Add warning if memory usage is too low (not utilizing available RAM)
  if (health.memory.process.used < 2000) { // Less than 2GB
    health.warnings = health.warnings || [];
    health.warnings.push('Low memory utilization - server can handle much higher load');
  }
  
  // Add warning if no working proxies
  if (health.proxies.working === 0) {
    health.warnings = health.warnings || [];
    health.warnings.push('No working proxies available');
    health.status = 'degraded';
  }
  
  res.json(health);
});

// API documentation with performance information
app.get('/', async (req, res) => {
  await cache.updateCacheStats();
  const memUsage = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
  const totalRAM = Math.round(os.totalmem() / 1024 / 1024 / 1024);
  
  res.json({
    name: 'High-Performance Proxy Bridge API - 16GB RAM Optimized',
    version: '6.0.0',
    description: 'Ultra-high performance proxy bridge optimized for 16GB RAM with hybrid caching and maximum concurrency',
    
    serverOptimization: {
      totalRAM: `${totalRAM}GB`,
      currentMemoryUsage: `${memUsage}MB`,
      maxConcurrency: MEMORY_OPTIMIZATION.maxConcurrentRequests,
      proxyTestConcurrency: MEMORY_OPTIMIZATION.proxyTestConcurrency,
      batchSize: MEMORY_OPTIMIZATION.batchSize,
      maxBufferSize: `${MEMORY_OPTIMIZATION.maxBufferSize / 1024 / 1024}MB`,
      configuration: 'High Performance Mode'
    },
    
    endpoints: {
      'Main Proxy': {
        'GET /proxies?url=<URL>': 'Proxy any URL with automatic video streaming support',
        'GET /proxies?url=<URL>&nocache=1': 'Bypass cache (automatically done for videos)'
      },
      'Statistics & Monitoring': {
        'GET /proxies/stats': 'Get comprehensive proxy and cache statistics',
        'GET /health': 'System health check with memory information',
        'GET /performance': 'Detailed performance monitoring',
        'GET /memory': 'Real-time memory usage statistics'
      },
      'Cache Management': {
        'GET /proxies/cache': 'View cache statistics and streaming info',
        'GET /proxies/cache?entries=1': 'View cached entries (top 100)',
        'DELETE /proxies/cache': 'Clear all cache',
        'DELETE /proxies/cache?url=<URL>': 'Delete specific cache entry',
        'POST /proxies/cache/reset': 'Force manual cache reset'
      },
      'Proxy Management': {
        'POST /proxies/test': 'Manually trigger proxy testing',
        'POST /proxies/fetch': 'Manually fetch new proxies'
      },
      'Documentation': {
        'GET /': 'This documentation',
        'GET /dashboard': 'Web dashboard interface'
      }
    },

    performanceFeatures: [
      'ðŸš€ 16GB RAM optimized for maximum performance',
      'âš¡ Up to ' + MEMORY_OPTIMIZATION.maxConcurrentRequests + ' concurrent requests',
      'ðŸ§  Hybrid cache system: File + Memory for ultra-fast access',
      'ðŸ“Š Real-time memory monitoring and optimization',
      'ðŸ”„ Auto-scaling proxy testing (' + MEMORY_OPTIMIZATION.proxyTestConcurrency + ' concurrent)',
      'ðŸ’¾ Intelligent memory buffer management',
      'ðŸ“ˆ Performance tracking and optimization',
      'ðŸŽ¯ Smart proxy selection with load balancing'
    ],

    memoryOptimization: [
      'ðŸ“ File-based cache (200MB) + Memory cache (500MB)',
      'ðŸ”„ Auto-reset every 3 hours to prevent memory bloat',
      'ðŸ§¹ Smart cleanup and memory management',
      'ðŸ“Š In-memory proxy metadata and performance tracking',
      'âš¡ Pre-calculated proxy scores for faster selection',
      'ðŸš€ Large file buffering up to 512MB',
      'ðŸ’¡ Automatic memory usage monitoring',
      'ðŸŽ¯ Dynamic optimization based on available RAM'
    ],

    videoStreamingFeatures: [
      'ðŸŽ¬ Full HTTP range request support for video streaming',
      'ðŸ“± Mobile-friendly video playback with seeking',
      'âš¡ Smart cache bypass for large files and videos',
      'ðŸŽ¯ Proper HTTP 206 Partial Content responses',
      'ðŸ“º Support for all video formats (MP4, WebM, MKV, etc.)',
      'ðŸ”„ Seamless seeking and buffering',
      'ðŸ’¾ Intelligent caching for small files only',
      'ðŸš« Automatic detection of streaming content'
    ],

    cacheSystem: {
      type: 'Hybrid: File-based + In-memory with auto-reset',
      fileCache: {
        file: 'cache.txt',
        maxSize: '200MB',
        resetInterval: '3 hours'
      },
      memoryCache: {
        maxSize: '500MB',
        ttl: '30 minutes',
        entries: cache.memoryCache?.size || 0
      },
      currentStats: cache.getStats(),
      benefits: [
        'Ultra-fast memory access for frequent requests',
        'Persistent file storage survives restarts',
        'Automatic cleanup and reset cycles',
        'Smart size management prevents bloat',
        'Detailed performance analytics'
      ]
    },

    examples: {
      webpage: '/proxies?url=https://example.com',
      video: '/proxies?url=https://example.com/video.mp4',
      api: '/proxies?url=https://api.example.com/data.json',
      largeFile: '/proxies?url=https://example.com/large-file.zip',
      streaming: '/proxies?url=https://streaming-service.com/content'
    },

    highPerformanceConfig: MEMORY_OPTIMIZATION,

    troubleshooting: {
      videoStreaming: 'Full range request support - no lag or buffering issues',
      largeFiles: 'Files up to 512MB supported with efficient memory management',
      concurrency: 'Up to ' + MEMORY_OPTIMIZATION.maxConcurrentRequests + ' concurrent requests supported',
      memoryUsage: 'Optimized for 16GB RAM - automatically scales performance',
      proxyTesting: 'High-speed testing with ' + MEMORY_OPTIMIZATION.proxyTestConcurrency + ' concurrent tests',
      caching: 'Hybrid cache system provides optimal performance',
      monitoring: 'Real-time performance monitoring available'
    },

    currentStats: {
      proxies: proxyManager.getStats(),
      cache: cache.getStats(),
      memory: {
        current: `${memUsage}MB`,
        total: `${totalRAM}GB`,
        optimization: 'High Performance Mode Active'
      },
      uptime: Math.round(process.uptime()) + 's'
    }
  });
});

// Graceful shutdown with enhanced cleanup
const gracefulShutdown = (signal) => {
  console.log(`ðŸ›‘ ${signal} received, shutting down gracefully...`);
  
  // Clear proxy intervals
  Object.values(proxyManager.intervals).forEach(interval => {
    if (interval) clearInterval(interval);
  });
  
  // Cleanup proxy manager
  proxyManager.destroy();
  
  // Cleanup cache
  cache.destroy();
  
  console.log('âœ… Cleanup completed, exiting...');
  process.exit(0);
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

process.on('uncaughtException', (error) => {
  console.error('Uncaught Exception:', error);
  gracefulShutdown('UNCAUGHT_EXCEPTION');
});

// Set Node.js memory limits for high RAM usage
if (process.env.NODE_OPTIONS !== `--max-old-space-size=${MEMORY_OPTIMIZATION.maxOldSpaceSize}`) {
  console.log(`ðŸ’¡ For optimal performance with 16GB RAM, set NODE_OPTIONS=--max-old-space-size=${MEMORY_OPTIMIZATION.maxOldSpaceSize}`);
}

// Start server
app.listen(PORT, () => {
  const memUsage = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
  const totalRAM = Math.round(os.totalmem() / 1024 / 1024 / 1024);
  
  console.log(`ðŸš€ High-Performance Proxy Bridge API running on port ${PORT}`);
  console.log(`ðŸ’¾ Server RAM: ${totalRAM}GB (Current usage: ${memUsage}MB)`);
  console.log(`âš¡ Max concurrent requests: ${MEMORY_OPTIMIZATION.maxConcurrentRequests}`);
  console.log(`ðŸ§ª Proxy testing concurrency: ${MEMORY_OPTIMIZATION.proxyTestConcurrency}`);
  console.log(`ðŸ“¦ Batch size: ${MEMORY_OPTIMIZATION.batchSize}`);
  console.log(`ðŸ—ƒï¸ Max buffer size: ${MEMORY_OPTIMIZATION.maxBufferSize / 1024 / 1024}MB`);
  console.log(``);
  console.log(`ðŸ“– Documentation: http://localhost:${PORT}/`);
  console.log(`ðŸŒ Standard: http://localhost:${PORT}/proxies?url=https://httpbin.org/ip`);
  console.log(`ðŸŽ¬ Video: http://localhost:${PORT}/proxies?url=https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4`);
  console.log(`ðŸ“Š Stats: http://localhost:${PORT}/proxies/stats`);
  console.log(`ðŸ’¾ Cache: http://localhost:${PORT}/proxies/cache?entries=1`);
  console.log(`ðŸ“ˆ Performance: http://localhost:${PORT}/performance`);
  console.log(`ðŸ’» Memory: http://localhost:${PORT}/memory`);
  console.log(`â¤ï¸ Health: http://localhost:${PORT}/health`);
  console.log(`ðŸŽ›ï¸ Dashboard: http://localhost:${PORT}/dashboard`);
  console.log(``);
  console.log(`ðŸ“ Cache: cache.txt (200MB file + 500MB memory, 3-hour auto-reset)`);
  console.log(`ðŸš€ Performance Mode: HIGH (16GB RAM Optimized)`);
  
  // Start background tasks
  proxyManager.startBackgroundTasks();
  
  // Log memory optimization status
  setTimeout(() => {
    const currentMem = Math.round(process.memoryUsage().heapUsed / 1024 / 1024);
    console.log(`ðŸ“Š Initial memory usage: ${currentMem}MB / ${totalRAM}GB available`);
    console.log(`ðŸŽ¯ Target memory utilization: 8-12GB for optimal performance`);
  }, 5000);
});

module.exports = { app, proxyManager, cache, MEMORY_OPTIMIZATION };
